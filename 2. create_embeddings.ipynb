{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nasif12/home_if12/l_schewinski/.conda/envs/l-schewinski-tp-4/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import esm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (10): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (12): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (13): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (14): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (15): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (16): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (17): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (18): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (19): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (20): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (21): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (22): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (23): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (24): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (25): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (26): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (27): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (28): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (29): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (30): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (31): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (32): TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loadsm the model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/OsmoticStress_with_binary_positions_padded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[[\"Uniprot_ID\", \"full_sequence\"]].drop_duplicates()\n",
    "df_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2490, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[~df_clean['full_sequence'].apply(lambda x: isinstance(x, float))]\n",
    "df_clean['full_sequence'] = df_clean['full_sequence'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_ID</th>\n",
       "      <th>full_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P38174</td>\n",
       "      <td>MTDAEIENSPASDLKELNLENEGVEQQDQAKADESDPVESKKKKNK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P06169</td>\n",
       "      <td>MSEITLGKYLFERLKQVNVNTVFGLPGDFNLSLLDKIYEVEGMRWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P00359</td>\n",
       "      <td>MVRVAINGFGRIGRLVMRIALSRPNVEVVALNDPFITNDYAAYMFK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P37292</td>\n",
       "      <td>MFPRASALAKCMATVHRRGLLTSGAQSLVSKPVSEGDPEMFDILQQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>P38887</td>\n",
       "      <td>MILKLVHCLVALTGLIFAKPYQQQQAVLAPSQDVPLRDIHIGDINF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>P53093</td>\n",
       "      <td>MSYGREDTTIEPDFIEPDAPLAASGGVADNIGGTMQNSGSRGTLDE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>Q04772</td>\n",
       "      <td>MSSDGMNRDVSNSKPNVRFAAPQRLSVAHPAISSPLHMPMSKSSRK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>P21192</td>\n",
       "      <td>MDNVVDPWYINPSGFAKDTQDEEYVQHHDNVNPTIPPPDNYILNNE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>Q03687</td>\n",
       "      <td>MSTTGPLDATLIRDVAVATATKASYDMSDTLYSYLPKVDQFYIPEW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2441 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Uniprot_ID                                      full_sequence\n",
       "0        P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...\n",
       "1        P38174  MTDAEIENSPASDLKELNLENEGVEQQDQAKADESDPVESKKKKNK...\n",
       "2        P06169  MSEITLGKYLFERLKQVNVNTVFGLPGDFNLSLLDKIYEVEGMRWA...\n",
       "3        P00359  MVRVAINGFGRIGRLVMRIALSRPNVEVVALNDPFITNDYAAYMFK...\n",
       "5        P37292  MFPRASALAKCMATVHRRGLLTSGAQSLVSKPVSEGDPEMFDILQQ...\n",
       "...         ...                                                ...\n",
       "2485     P38887  MILKLVHCLVALTGLIFAKPYQQQQAVLAPSQDVPLRDIHIGDINF...\n",
       "2486     P53093  MSYGREDTTIEPDFIEPDAPLAASGGVADNIGGTMQNSGSRGTLDE...\n",
       "2487     Q04772  MSSDGMNRDVSNSKPNVRFAAPQRLSVAHPAISSPLHMPMSKSSRK...\n",
       "2488     P21192  MDNVVDPWYINPSGFAKDTQDEEYVQHHDNVNPTIPPPDNYILNNE...\n",
       "2489     Q03687  MSTTGPLDATLIRDVAVATATKASYDMSDTLYSYLPKVDQFYIPEW...\n",
       "\n",
       "[2441 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_excel('data/OsmoticStress.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Qvalue(LiP) information again to dataframe to get the sequences with lowest Qvalue(LiP) to create the embeddings\n",
    "df_clean = pd.merge(df_clean, df_full[['Uniprot_ID', 'Qvalue(LiP)']], on='Uniprot_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_ID</th>\n",
       "      <th>full_sequence</th>\n",
       "      <th>Qvalue(LiP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.034862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.039093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.042584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.048552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27139</th>\n",
       "      <td>P38887</td>\n",
       "      <td>MILKLVHCLVALTGLIFAKPYQQQQAVLAPSQDVPLRDIHIGDINF...</td>\n",
       "      <td>0.376924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27140</th>\n",
       "      <td>P53093</td>\n",
       "      <td>MSYGREDTTIEPDFIEPDAPLAASGGVADNIGGTMQNSGSRGTLDE...</td>\n",
       "      <td>0.381210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27141</th>\n",
       "      <td>Q04772</td>\n",
       "      <td>MSSDGMNRDVSNSKPNVRFAAPQRLSVAHPAISSPLHMPMSKSSRK...</td>\n",
       "      <td>0.381696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27142</th>\n",
       "      <td>P21192</td>\n",
       "      <td>MDNVVDPWYINPSGFAKDTQDEEYVQHHDNVNPTIPPPDNYILNNE...</td>\n",
       "      <td>0.382355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27143</th>\n",
       "      <td>Q03687</td>\n",
       "      <td>MSTTGPLDATLIRDVAVATATKASYDMSDTLYSYLPKVDQFYIPEW...</td>\n",
       "      <td>0.388780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Uniprot_ID                                      full_sequence  \\\n",
       "0         P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "1         P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "2         P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "3         P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "4         P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "...          ...                                                ...   \n",
       "27139     P38887  MILKLVHCLVALTGLIFAKPYQQQQAVLAPSQDVPLRDIHIGDINF...   \n",
       "27140     P53093  MSYGREDTTIEPDFIEPDAPLAASGGVADNIGGTMQNSGSRGTLDE...   \n",
       "27141     Q04772  MSSDGMNRDVSNSKPNVRFAAPQRLSVAHPAISSPLHMPMSKSSRK...   \n",
       "27142     P21192  MDNVVDPWYINPSGFAKDTQDEEYVQHHDNVNPTIPPPDNYILNNE...   \n",
       "27143     Q03687  MSTTGPLDATLIRDVAVATATKASYDMSDTLYSYLPKVDQFYIPEW...   \n",
       "\n",
       "       Qvalue(LiP)  \n",
       "0         0.003686  \n",
       "1         0.034862  \n",
       "2         0.039093  \n",
       "3         0.042584  \n",
       "4         0.048552  \n",
       "...            ...  \n",
       "27139     0.376924  \n",
       "27140     0.381210  \n",
       "27141     0.381696  \n",
       "27142     0.382355  \n",
       "27143     0.388780  \n",
       "\n",
       "[27144 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_ID</th>\n",
       "      <th>full_sequence</th>\n",
       "      <th>Qvalue(LiP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>P06169</td>\n",
       "      <td>MSEITLGKYLFERLKQVNVNTVFGLPGDFNLSLLDKIYEVEGMRWA...</td>\n",
       "      <td>0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P38174</td>\n",
       "      <td>MTDAEIENSPASDLKELNLENEGVEQQDQAKADESDPVESKKKKNK...</td>\n",
       "      <td>0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>P00359</td>\n",
       "      <td>MVRVAINGFGRIGRLVMRIALSRPNVEVVALNDPFITNDYAAYMFK...</td>\n",
       "      <td>0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>P37292</td>\n",
       "      <td>MFPRASALAKCMATVHRRGLLTSGAQSLVSKPVSEGDPEMFDILQQ...</td>\n",
       "      <td>0.005126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Uniprot_ID                                      full_sequence  Qvalue(LiP)\n",
       "0       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...     0.003686\n",
       "36      P06169  MSEITLGKYLFERLKQVNVNTVFGLPGDFNLSLLDKIYEVEGMRWA...     0.003686\n",
       "18      P38174  MTDAEIENSPASDLKELNLENEGVEQQDQAKADESDPVESKKKKNK...     0.003686\n",
       "215     P00359  MVRVAINGFGRIGRLVMRIALSRPNVEVVALNDPFITNDYAAYMFK...     0.003686\n",
       "266     P37292  MFPRASALAKCMATVHRRGLLTSGAQSLVSKPVSEGDPEMFDILQQ...     0.005126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df_clean.sort_values(by='Qvalue(LiP)', ascending=True)\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = sorted_df['full_sequence'].str.len().max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def generate_embeddings(model, alphabet, sequences):\n",
    "    \"\"\"\n",
    "    Function to generate the embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    \n",
    "    for sequence in tqdm.tqdm(sequences, desc=\"Generating Embeddings\"):\n",
    "        data = [(0, sequence)]\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            results = model(batch_tokens, repr_layers=[33]) \n",
    "            token_embeddings = results['representations'][33]\n",
    "\n",
    "        # Average embeddings across all tokens and convert to numpy\n",
    "        # averaged_embedding = token_embeddings.mean(dim=1).numpy()\n",
    "        # embeddings.append(averaged_embedding)\n",
    "\n",
    "        # Create full embeddings\n",
    "        full_embedding = token_embeddings.squeeze().numpy()\n",
    "        embeddings.append(full_embedding)\n",
    "    \n",
    "    #return np.vstack(embeddings) \n",
    "    return embeddings\n",
    "\n",
    "df_test = df_clean[:500].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_ID</th>\n",
       "      <th>full_sequence</th>\n",
       "      <th>Qvalue(LiP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.034862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.039093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.042584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.048552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Q00055</td>\n",
       "      <td>MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...</td>\n",
       "      <td>0.292011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Q00055</td>\n",
       "      <td>MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...</td>\n",
       "      <td>0.361558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>P49626</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "      <td>0.007762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>P49626</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "      <td>0.027188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>P49626</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "      <td>0.036417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Uniprot_ID                                      full_sequence  Qvalue(LiP)\n",
       "0       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...     0.003686\n",
       "1       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...     0.034862\n",
       "2       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...     0.039093\n",
       "3       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...     0.042584\n",
       "4       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...     0.048552\n",
       "..         ...                                                ...          ...\n",
       "495     Q00055  MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...     0.292011\n",
       "496     Q00055  MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...     0.361558\n",
       "497     P49626  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...     0.007762\n",
       "498     P49626  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...     0.027188\n",
       "499     P49626  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...     0.036417\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequence, target_length=1000, pad_token='<pad>'):\n",
    "    padding_length = target_length - len(sequence)\n",
    "    return sequence + pad_token * padding_length\n",
    "\n",
    "# Apply padding to each sequence with <pad>\n",
    "df_test['padded_sequence'] = df_test['full_sequence'].apply(lambda x: pad_sequence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_ID</th>\n",
       "      <th>full_sequence</th>\n",
       "      <th>Qvalue(LiP)</th>\n",
       "      <th>padded_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.039093</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.042584</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P15703</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "      <td>0.048552</td>\n",
       "      <td>MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Q00055</td>\n",
       "      <td>MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...</td>\n",
       "      <td>0.292011</td>\n",
       "      <td>MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Q00055</td>\n",
       "      <td>MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...</td>\n",
       "      <td>0.361558</td>\n",
       "      <td>MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>P49626</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>P49626</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>P49626</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "      <td>0.036417</td>\n",
       "      <td>MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Uniprot_ID                                      full_sequence  \\\n",
       "0       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "1       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "2       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "3       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "4       P15703  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...   \n",
       "..         ...                                                ...   \n",
       "495     Q00055  MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...   \n",
       "496     Q00055  MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...   \n",
       "497     P49626  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...   \n",
       "498     P49626  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...   \n",
       "499     P49626  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...   \n",
       "\n",
       "     Qvalue(LiP)                                    padded_sequence  \n",
       "0       0.003686  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...  \n",
       "1       0.034862  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...  \n",
       "2       0.039093  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...  \n",
       "3       0.042584  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...  \n",
       "4       0.048552  MRFSTTLATAATALFFTASQVSAIGELAFNLGVKNNDGTCKSTSDY...  \n",
       "..           ...                                                ...  \n",
       "495     0.292011  MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...  \n",
       "496     0.361558  MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWG...  \n",
       "497     0.007762  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...  \n",
       "498     0.027188  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...  \n",
       "499     0.036417  MSRPQVTVHSLTGEATANALPLPAVFSAPIRPDIVHTVFTSVNKNK...  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the padding is correct\n",
    "df_test['full_sequence_length'] = df_test['full_sequence'].apply(len)\n",
    "df_test['num_pad_tokens'] = df_test['padded_sequence'].apply(lambda x: x.count('<pad>'))\n",
    "df_test['padded_sequence_length'] = df_test['full_sequence_length'] + df_test['num_pad_tokens']\n",
    "df_test['expected_padded_length'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 500/500 [1:20:04<00:00,  9.61s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate the embeddings!\n",
    "\n",
    "sequences = df_test['padded_sequence'].tolist()\n",
    "embeddings = generate_embeddings(model, alphabet, sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['full_embedding'] = [e.tolist() for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_pickle('data/embeddings_new.pkl', protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-l-schewinski-tp-4]",
   "language": "python",
   "name": "conda-env-.conda-l-schewinski-tp-4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
