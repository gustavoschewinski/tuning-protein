{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein conformational changes between conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZFgPUCYU_Fm",
    "outputId": "b0c9312a-444f-451d-d004-b73ce472ab20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Bio in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: biopython>=1.80 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from Bio) (1.83)\n",
      "Requirement already satisfied: requests in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from Bio) (2.26.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from Bio) (4.62.3)\n",
      "Requirement already satisfied: mygene in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from Bio) (3.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from Bio) (2.0.3)\n",
      "Requirement already satisfied: pooch in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from Bio) (1.8.2)\n",
      "Requirement already satisfied: gprofiler-official in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from Bio) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from biopython>=1.80->Bio) (1.24.4)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from mygene->Bio) (0.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from pandas->Bio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from pandas->Bio) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from pandas->Bio) (2023.4)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from pooch->Bio) (4.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from pooch->Bio) (21.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from requests->Bio) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from requests->Bio) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from requests->Bio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from requests->Bio) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from tqdm->Bio) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch->Bio) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aliprandi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1Gnz2n7PnGV",
    "outputId": "b2d18c44-b630-44e0-e24b-c7a4d2b22c9a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALIPRA~1\\AppData\\Local\\Temp/ipykernel_9772/2249737261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgdrive_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/content/gdrive/MyDrive/UFSC/Faculdade/tum/Genomics'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/UFSC/Faculdade/tum/Genomics'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "print(sorted(os.listdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2gkjMaEQ5eO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('OsmoticStress.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tif0zHXPTkyh"
   },
   "outputs": [],
   "source": [
    "df = df[['Uniprot_ID', 'Peptide_sequence', 'Log2FC(LiP_norm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sqMOUhaFTILF",
    "outputId": "72e19efc-5aab-4eb5-e1f0-a331dfaad718"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuEPZVtCUbQ2"
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "def read_fasta_to_dict(file_path):\n",
    "    sequences = {}\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        # Splitting the record.id to extract the UniProt ID if necessary\n",
    "        uniprot_id = record.id.split('|')[1]  # Adjust this as per your FASTA file's format\n",
    "        sequences[uniprot_id] = str(record.seq)\n",
    "    return sequences\n",
    "\n",
    "# Provide the path to your FASTA file\n",
    "fasta_file_path = 'UP000002311_559292.fasta'\n",
    "sequences = read_fasta_to_dict(fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpp4BI2MVFxG"
   },
   "outputs": [],
   "source": [
    "df[\"full_sequence\"] = df['Uniprot_ID'].map(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fYnXCETCVpqB",
    "outputId": "23517f27-a782-432c-eb38-d495c6bf3b0e"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0awHysFVvF2"
   },
   "outputs": [],
   "source": [
    "df.to_csv(gdrive_path + \"/processed_yeast_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Split training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the model from hugging face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the following checkpoints:\n",
    "\n",
    "\n",
    "| Checkpoint name | Num layers | Num parameters |\n",
    "|------------------------------|----|----------|\n",
    "| `esm2_t48_15B_UR50D`         | 48 | 15B     |\n",
    "| `esm2_t36_3B_UR50D`          | 36 | 3B      |\n",
    "| `esm2_t33_650M_UR50D`        | 33 | 650M    |\n",
    "| `esm2_t30_150M_UR50D`        | 30 | 150M    |\n",
    "| `esm2_t12_35M_UR50D`         | 12 | 35M     |\n",
    "| `esm2_t6_8M_UR50D`           | 6  | 8M      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/esm2_t6_8M_UR50D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LiP_norm = df['Log2FC(LiP_norm)']\n",
    "tokenizer_train, tokenizer_test, LiP_norm_train, LiP_norm_test = train_test_split(tokenizer, LiP_norm, test_size = 0.25)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
